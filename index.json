{"decks":{"01_Introduction/01-introduction-deck.html":{"deckId":null,"deckSubtitle":"1 - Introduction","deckTitle":"Deep Reinforcement Learning","deckUrl":"01_Introduction/01-introduction-deck.html"}},"index":{"000":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"0jl04jjjocc":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"}],"1956":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"2018":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"2019":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#machine-learning-is"}],"2020":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"2021":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"2022":[{"count":4,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":6,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"}],"2023":[{"count":4,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"}],"221":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"ability":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"able":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"about":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"abstract":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"accepted":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"actions":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"actively":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"actor":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"}],"adapt":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"adaptive":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"adaptivity":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"additional":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"advanced":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"advantage":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"adversarial":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"}],"agent":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"agents":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"aims":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"alammar2022diffusion":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion"}],"algebra":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"algorithm":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"}],"algorithms":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"}],"all":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"allow":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"allowed":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"allows":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"also":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"and":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-learning-hide-and-seek"},{"count":4,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-and-classification"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#reading-list"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#exercises"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"andrew":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence"}],"answer":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"anyone":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"application":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"applying":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#applying-different-perturbations"}],"approaches":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification-approaches"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"approximation":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-for-function-approximation"}],"architecture":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"}],"are":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"around":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"art":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"artificial":[{"count":3,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"associated":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"}],"automatic":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"automatically":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"autonomous":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"available":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#reading-list"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"avoid":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"balance":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"balancing":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"barto":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"based":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"became":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"become":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"been":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"behavior":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"better":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"between":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"biologically":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"bishop2006":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"blog":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"}],"book":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"break":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"brief":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"broad":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"}],"built":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"but":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"camera":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"can":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"capabilities":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"carry":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"cartoon":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#machine-learning-is"}],"categorization":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"}],"caveats":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"challenge":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"change":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"characteristic":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"cheatsheet2018":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"}],"choose":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"}],"classical":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"classification":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification-approaches"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-and-classification"}],"clustering":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"code":[{"count":3,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"collaborate":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"com":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"}],"commands":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"common":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"}],"communicate":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"computer":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"computers":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"concepts":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"conditioned":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"}],"confident":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"confine":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"consists":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"containing":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"}],"context":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"control":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"cooperating":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"cope":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"could":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"course":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"cowalski":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"critic":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"}],"crucial":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"cs221":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"cube":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"}],"cumulative":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"dall":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"}],"dalle2":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"}],"data":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"dataset":[{"count":3,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"}],"date":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"}],"dealing":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"deals":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"decide":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"}],"decision":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"deep":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":4,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":4,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"def":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"demonstration":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"descent":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"}],"describe":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"description":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"descriptions":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"develop":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"}],"dexterity":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"different":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#applying-different-perturbations"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#types-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#different-forms-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"}],"differentiation":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"difficult":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"diffusion":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion"}],"dimensional":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"discover":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"discuss":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"discussion":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"distinction":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#types-of-learning"}],"distributed":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"distribution":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"disturbances":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"does":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-this-person-does-not-exist"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"domain":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"done":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"dqn":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"}],"drl":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"dropped":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"during":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"dynamic":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"}],"each":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"}],"easy":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"either":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"electricity":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence"}],"else":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"embed":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"}],"encoded":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"enforce":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"engineering":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"enhance":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"enough":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"entire":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"entry":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"}],"environment":[{"count":3,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"environments":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"especially":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"eth":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"}],"even":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"every":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"everybody":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"everything":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"exam":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"example":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-learning-hide-and-seek"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-this-person-does-not-exist"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#simple-example-learning-from-experience"}],"examples":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"exercise":[{"count":4,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"exercises":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#exercises"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"exist":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-this-person-does-not-exist"}],"expected":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"experience":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#simple-example-learning-from-experience"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"}],"explain":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"explanation":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"exploit":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"exploitation":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"exploration":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"explore":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"external":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"}],"fashion":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"feature":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"features":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"}],"first":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"fit":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"flying":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"}],"focus":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"}],"focussed":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"following":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"}],"for":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-for-function-approximation"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#exercises"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"foreign":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"form":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"formal":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"formalization":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"}],"formalize":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"forms":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#different-forms-of-learning"}],"free":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"}],"friday":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"from":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-learning-hide-and-seek"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#simple-example-learning-from-experience"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#machine-learning-is"}],"function":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-for-function-approximation"}],"functions":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"gan":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"}],"gaussian":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"general":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"generated":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"generative":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"}],"get":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"given":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"goal":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"goals":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"good":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"goodfellow2016":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"google":[{"count":3,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"gradient":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"}],"gradually":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"groups":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"guidance":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"hand":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"hard":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"has":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"have":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"helicopter":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"}],"hide":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-learning-hide-and-seek"}],"hierarchy":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"high":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"higher":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"}],"ho2020diffusion":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion"}],"honor":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"household":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"how":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":5,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"html":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"https":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"}],"human":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"humans":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"hypothesis":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"icra":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"images":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#machine-learning-is"}],"implicit":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"}],"important":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"improve":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"independently":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"influences":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"}],"information":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-today"}],"ingredient":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"initially":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"input":[{"count":3,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"instance":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"instant":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"instead":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"institute":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"intelligence":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"},{"count":5,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"intelligent":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"intelligently":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"interacting":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"interaction":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"interest":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"interface":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"into":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"introduction":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"inverse":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"}],"itself":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"just":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"kleincs188":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"know":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"knowledge":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"known":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"lab":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"}],"label":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"}],"lands":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"language":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"languages":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"layers":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"learn":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"learner":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"learning":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-learning-hide-and-seek"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"},{"count":4,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reinforcement"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reinforcement-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#types-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#different-forms-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-as-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#simple-example-learning-from-experience"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#machine-learning-is"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#machine-learning"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#reading-list"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#overview-today"}],"learns":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"learnt":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"least":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"lecture":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#overview-today"}],"lens":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"less":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"level":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"}],"levels":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"}],"like":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"limited":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"line":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"linear":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"list":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"locomotion":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"logic":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"long":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"machine":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#machine-learning-is"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#machine-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-today"}],"machines":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"made":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"make":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"making":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"manage":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"manipulation":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"}],"many":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"map":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"mathematics":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"maximization":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"maximize":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"maximizes":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"may":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"mccarthy":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"mdp":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"}],"meaning":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"means":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"measure":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"mechanism":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"meetings":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"methods":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"might":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"miki2022locomotion":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"}],"miss":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"mixture":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"mobile":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"model":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"modelling":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"models":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"module":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"more":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"morning":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"most":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"much":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"multi":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"multiple":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"must":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"nearest":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"neighbors":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"networks":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"neural":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"new":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"non":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"none":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"nonetheless":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"not":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-this-person-does-not-exist"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"novelty":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"number":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"numerical":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"nvidia":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"}],"observable":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"obvious":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"one":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"online":[{"count":3,"slide":"01_Introduction/01-introduction-deck.html#reading-list"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"only":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"openai":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"}],"openai2019hideandseek":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-learning-hide-and-seek"}],"openai2019solving":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#applying-different-perturbations"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"optimal":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"optimization":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"}],"options":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"oral":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"other":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"out":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"outpainting":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"}],"overview":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#overview-today"}],"own":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"paper":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"parametric":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"partially":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"past":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"pdf":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"perform":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"performance":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"person":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-this-person-does-not-exist"}],"persons":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"perturbations":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#applying-different-perturbations"}],"phone":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"place":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"pointing":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"points":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"pole":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"policy":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":4,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"}],"possible":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"post":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"prediction":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"}],"predictions":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"preliminary":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"prerequisite":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"present":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"presentation":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"prestructuring":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"presupposes":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"prime":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"probabilities":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"probability":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"problem":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"}],"problems":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"process":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"progan":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"}],"programming":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"programs":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"progressive":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"}],"promise":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"properties":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"pseudo":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"}],"python":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"question":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"questions":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"quite":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"randomization":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"raw":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"reach":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"reading":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"real":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"reality":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"recap":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"}],"references":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#references"}],"regression":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-and-classification"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-for-function-approximation"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-as-learning"}],"reinforcement":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reinforcement"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reinforcement-learning"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#reading-list"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-today"}],"related":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"relying":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"remarkable":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"remarks":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"repository":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"represent":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"representation":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"represented":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"required":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"research":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"responds":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"reward":[{"count":3,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":4,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"rewards":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"robot":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"robotic":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"robotics":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"rubik":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"}],"rubiks":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"}],"rules":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"same":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"scalar":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"schilling2022":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research-2"}],"science":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"second":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"see":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"seek":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-learning-hide-and-seek"}],"seemingly":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"sequences":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"set":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"shared":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"sheet":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"short":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"should":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"show":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"shows":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"signal":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"silver":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"silver2015":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"}],"similar":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"simple":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#simple-example-learning-from-experience"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"simulated":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"simulation":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"single":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"situations":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"skills":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"slides":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"slot":[{"count":3,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"small":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"solution":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#exercises"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"}],"solutions":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"solve":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"solving":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"}],"something":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"sota":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"}],"space":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"specific":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"specified":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"spectrum":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"}],"stanford":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"state":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"sticking":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"}],"strategy":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"structure":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"submitted":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"such":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"supervised":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"}],"sutton":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"sutton2018":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"svm":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"symbolic":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"}],"systems":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"take":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"takes":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"target":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"}],"task":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"tasks":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"teacher":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"teams":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"tentative":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"}],"testing":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"text":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"that":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"the":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#google-translate"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":3,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence"},{"count":4,"slide":"01_Introduction/01-introduction-deck.html#exercises"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#general-information"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-today"}],"them":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"then":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"there":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"these":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"}],"this":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-this-person-does-not-exist"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"those":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"three":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"through":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"time":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"times":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"today":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-today"}],"together":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"told":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"topics":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-today"}],"towards":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-today"}],"toyota":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"tradeoff":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"}],"train":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"training":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#pole-balancing"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"transform":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"translate":[{"count":4,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"translation":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"trials":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"tricks":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"tries":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"}],"true":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"try":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"trying":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"tuesday":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"turned":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"two":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"types":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#types-of-learning"}],"ucl":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#reading-list"}],"understand":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"understanding":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"unfamiliar":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"}],"unless":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"unpredictable":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"unstructured":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"}],"unsupervised":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"use":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"useful":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"users":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"using":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#regression-example"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"usually":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"value":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},{"count":4,"slide":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"}],"variation":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"}],"variety":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"very":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"video":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"}],"virtual":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"voice":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"want":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#unsupervised"}],"way":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"}],"website":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"}],"week":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"weeks":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"well":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"weng2018rl":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"what":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"}],"which":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#promise-of-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"}],"will":[{"count":3,"slide":"01_Introduction/01-introduction-deck.html#exercises"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#the-lecture"}],"with":[{"count":5,"slide":"01_Introduction/01-introduction-deck.html#my-own-research"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#supervised-learning"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"}],"wolf2018progan":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"}],"words":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"world":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#google-translate"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"}],"write":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"writeup":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"www":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"}],"x4o8pojmf0w":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"}],"years":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"}],"yield":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}],"you":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#clustering"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#google-translate"},{"count":2,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"}],"your":[{"count":2,"slide":"01_Introduction/01-introduction-deck.html#google-translate"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#exercises"}],"youtube":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"},{"count":1,"slide":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"}],"zrich":[{"count":1,"slide":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"}]},"slides":{"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"a-spectrum-of-intelligence","slideTitle":"A spectrum of intelligence","slideUrl":"01_Introduction/01-introduction-deck.html#a-spectrum-of-intelligence"},"01_Introduction/01-introduction-deck.html#applying-different-perturbations":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"applying-different-perturbations","slideTitle":"Applying different Perturbations","slideUrl":"01_Introduction/01-introduction-deck.html#applying-different-perturbations"},"01_Introduction/01-introduction-deck.html#artificial-intelligence":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"artificial-intelligence","slideTitle":"Artificial Intelligence","slideUrl":"01_Introduction/01-introduction-deck.html#artificial-intelligence"},"01_Introduction/01-introduction-deck.html#artificial-intelligence-1":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"artificial-intelligence-1","slideTitle":"Artificial Intelligence","slideUrl":"01_Introduction/01-introduction-deck.html#artificial-intelligence-1"},"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"categorization-of-reinforcement-learning-agents","slideTitle":"Categorization of Reinforcement Learning Agents","slideUrl":"01_Introduction/01-introduction-deck.html#categorization-of-reinforcement-learning-agents"},"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"classification---promise-of-deep-neural-networks","slideTitle":"Classification - Promise of Deep Neural Networks","slideUrl":"01_Introduction/01-introduction-deck.html#classification---promise-of-deep-neural-networks"},"01_Introduction/01-introduction-deck.html#classification-approaches":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"classification-approaches","slideTitle":"Classification: Approaches","slideUrl":"01_Introduction/01-introduction-deck.html#classification-approaches"},"01_Introduction/01-introduction-deck.html#clustering":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"clustering","slideTitle":"Clustering","slideUrl":"01_Introduction/01-introduction-deck.html#clustering"},"01_Introduction/01-introduction-deck.html#different-forms-of-learning":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"different-forms-of-learning","slideTitle":"Different forms of Learning","slideUrl":"01_Introduction/01-introduction-deck.html#different-forms-of-learning"},"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"example-generative-adversarial-networks","slideTitle":"Example: Generative Adversarial Networks","slideUrl":"01_Introduction/01-introduction-deck.html#example-generative-adversarial-networks"},"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"example-generative-models-diffusion","slideTitle":"Example: Generative Models  Diffusion","slideUrl":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion"},"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-2":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"example-generative-models-diffusion-2","slideTitle":"Example: Generative Models  Diffusion 2","slideUrl":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-2"},"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"example-generative-models-diffusion-3","slideTitle":"Example: Generative Models  Diffusion 3","slideUrl":"01_Introduction/01-introduction-deck.html#example-generative-models-diffusion-3"},"01_Introduction/01-introduction-deck.html#example-learning-hide-and-seek":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"example-learning-hide-and-seek","slideTitle":"Example: Learning Hide-and-seek","slideUrl":"01_Introduction/01-introduction-deck.html#example-learning-hide-and-seek"},"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"example-outpainting-with-dall-e-2","slideTitle":"Example: Outpainting with Dall-E 2","slideUrl":"01_Introduction/01-introduction-deck.html#example-outpainting-with-dall-e-2"},"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"example-solving-a-rubiks-cube-with-a-robot-hand","slideTitle":"Example: Solving a Rubiks Cube with a Robot Hand","slideUrl":"01_Introduction/01-introduction-deck.html#example-solving-a-rubiks-cube-with-a-robot-hand"},"01_Introduction/01-introduction-deck.html#example-this-person-does-not-exist":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"example-this-person-does-not-exist","slideTitle":"Example: This person does not exist","slideUrl":"01_Introduction/01-introduction-deck.html#example-this-person-does-not-exist"},"01_Introduction/01-introduction-deck.html#exercises":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"exercises","slideTitle":"Exercises","slideUrl":"01_Introduction/01-introduction-deck.html#exercises"},"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"explore-or-exploit-information-for-decision-making","slideTitle":"Explore or Exploit Information for Decision Making","slideUrl":"01_Introduction/01-introduction-deck.html#explore-or-exploit-information-for-decision-making"},"01_Introduction/01-introduction-deck.html#general-information":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"general-information","slideTitle":"General Information","slideUrl":"01_Introduction/01-introduction-deck.html#general-information"},"01_Introduction/01-introduction-deck.html#google-translate":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"google-translate","slideTitle":"Google Translate","slideUrl":"01_Introduction/01-introduction-deck.html#google-translate"},"01_Introduction/01-introduction-deck.html#learning-from-demonstration":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"learning-from-demonstration","slideTitle":"Learning from demonstration","slideUrl":"01_Introduction/01-introduction-deck.html#learning-from-demonstration"},"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"learning-is-the-answer-to-a-number-of-important-questions","slideTitle":"Learning is the answer to a number of important questions:","slideUrl":"01_Introduction/01-introduction-deck.html#learning-is-the-answer-to-a-number-of-important-questions"},"01_Introduction/01-introduction-deck.html#machine-learning":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"machine-learning","slideTitle":"Machine Learning","slideUrl":"01_Introduction/01-introduction-deck.html#machine-learning"},"01_Introduction/01-introduction-deck.html#machine-learning-is":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"machine-learning-is","slideTitle":"Machine Learning is ","slideUrl":"01_Introduction/01-introduction-deck.html#machine-learning-is"},"01_Introduction/01-introduction-deck.html#my-own-research":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"my-own-research","slideTitle":"My own research","slideUrl":"01_Introduction/01-introduction-deck.html#my-own-research"},"01_Introduction/01-introduction-deck.html#my-own-research-2":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"my-own-research-2","slideTitle":"My own research 2","slideUrl":"01_Introduction/01-introduction-deck.html#my-own-research-2"},"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"overview-common-ml-algorithms","slideTitle":"Overview common ML algorithms","slideUrl":"01_Introduction/01-introduction-deck.html#overview-common-ml-algorithms"},"01_Introduction/01-introduction-deck.html#overview-course-2-tentative":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"overview-course-2-tentative","slideTitle":"Overview course 2  tentative!","slideUrl":"01_Introduction/01-introduction-deck.html#overview-course-2-tentative"},"01_Introduction/01-introduction-deck.html#overview-lecture":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"overview-lecture","slideTitle":"Overview Lecture","slideUrl":"01_Introduction/01-introduction-deck.html#overview-lecture"},"01_Introduction/01-introduction-deck.html#overview-today":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"overview-today","slideTitle":"Overview today","slideUrl":"01_Introduction/01-introduction-deck.html#overview-today"},"01_Introduction/01-introduction-deck.html#pole-balancing":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"pole-balancing","slideTitle":"Pole balancing","slideUrl":"01_Introduction/01-introduction-deck.html#pole-balancing"},"01_Introduction/01-introduction-deck.html#promise-of-learning":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"promise-of-learning","slideTitle":"Promise of Learning","slideUrl":"01_Introduction/01-introduction-deck.html#promise-of-learning"},"01_Introduction/01-introduction-deck.html#reading-list":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"reading-list","slideTitle":"Reading List","slideUrl":"01_Introduction/01-introduction-deck.html#reading-list"},"01_Introduction/01-introduction-deck.html#references":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"references","slideTitle":"References","slideUrl":"01_Introduction/01-introduction-deck.html#references"},"01_Introduction/01-introduction-deck.html#regression-and-classification":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"regression-and-classification","slideTitle":"Regression and Classification","slideUrl":"01_Introduction/01-introduction-deck.html#regression-and-classification"},"01_Introduction/01-introduction-deck.html#regression-as-learning":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"regression-as-learning","slideTitle":"Regression as Learning","slideUrl":"01_Introduction/01-introduction-deck.html#regression-as-learning"},"01_Introduction/01-introduction-deck.html#regression-example":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"regression-example","slideTitle":"Regression Example","slideUrl":"01_Introduction/01-introduction-deck.html#regression-example"},"01_Introduction/01-introduction-deck.html#regression-for-function-approximation":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"regression-for-function-approximation","slideTitle":"Regression for Function Approximation","slideUrl":"01_Introduction/01-introduction-deck.html#regression-for-function-approximation"},"01_Introduction/01-introduction-deck.html#reinforcement":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"reinforcement","slideTitle":"Reinforcement Learning","slideUrl":"01_Introduction/01-introduction-deck.html#reinforcement"},"01_Introduction/01-introduction-deck.html#reinforcement-learning":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"reinforcement-learning","slideTitle":"Reinforcement Learning","slideUrl":"01_Introduction/01-introduction-deck.html#reinforcement-learning"},"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"remarks-on-state-of-the-art-for-drl-in-robotics","slideTitle":"Remarks on State-of-the-Art for DRL in Robotics","slideUrl":"01_Introduction/01-introduction-deck.html#remarks-on-state-of-the-art-for-drl-in-robotics"},"01_Introduction/01-introduction-deck.html#simple-example-learning-from-experience":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"simple-example-learning-from-experience","slideTitle":"Simple example: Learning from experience","slideUrl":"01_Introduction/01-introduction-deck.html#simple-example-learning-from-experience"},"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"sota-in-drl-for-locomotion","slideTitle":"SOTA in DRL for Locomotion","slideUrl":"01_Introduction/01-introduction-deck.html#sota-in-drl-for-locomotion"},"01_Introduction/01-introduction-deck.html#supervised-learning":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"supervised-learning","slideTitle":"Supervised Learning","slideUrl":"01_Introduction/01-introduction-deck.html#supervised-learning"},"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"task-how-to-automatically-learn-a-regression-line","slideTitle":"Task: How to automatically learn a regression line?","slideUrl":"01_Introduction/01-introduction-deck.html#task-how-to-automatically-learn-a-regression-line"},"01_Introduction/01-introduction-deck.html#the-lecture":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"the-lecture","slideTitle":"The Lecture","slideUrl":"01_Introduction/01-introduction-deck.html#the-lecture"},"01_Introduction/01-introduction-deck.html#the-reward-hypothesis":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"the-reward-hypothesis","slideTitle":"The reward hypothesis","slideUrl":"01_Introduction/01-introduction-deck.html#the-reward-hypothesis"},"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"two-broad-influences-in-ai","slideTitle":"Two broad influences in AI","slideUrl":"01_Introduction/01-introduction-deck.html#two-broad-influences-in-ai"},"01_Introduction/01-introduction-deck.html#types-of-learning":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"types-of-learning","slideTitle":"Types of Learning","slideUrl":"01_Introduction/01-introduction-deck.html#types-of-learning"},"01_Introduction/01-introduction-deck.html#unsupervised":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"unsupervised","slideTitle":"Unsupervised Learning","slideUrl":"01_Introduction/01-introduction-deck.html#unsupervised"},"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"video---learning-flying-stanford-helicopter","slideTitle":"Video - Learning Flying Stanford Helicopter","slideUrl":"01_Introduction/01-introduction-deck.html#video---learning-flying-stanford-helicopter"},"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"video-external-website---solving-rubiks-cube-with-a-robot-hand","slideTitle":"Video, External Website - Solving Rubiks Cube with a Robot Hand","slideUrl":"01_Introduction/01-introduction-deck.html#video-external-website---solving-rubiks-cube-with-a-robot-hand"},"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl":{"deckUrl":"01_Introduction/01-introduction-deck.html","slideId":"what-is-reinforcement-learning-rl","slideTitle":"What is Reinforcement Learning (RL)?","slideUrl":"01_Introduction/01-introduction-deck.html#what-is-reinforcement-learning-rl"}}}